{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24fb28e",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "\n",
    "# config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class TrainingConfig:\n",
    "    \"\"\"Configuration class for training parameters\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Paths\n",
    "        self.BASE_DIR = Path(os.path.dirname(os.path.abspath(__file__))).parent\n",
    "        self.DATA_DIR = self.BASE_DIR / \"data\"\n",
    "        self.MODELS_DIR = self.BASE_DIR / \"models\"\n",
    "\n",
    "        # Data paths\n",
    "        self.TRAIN_LABELS_PATH = self.DATA_DIR / \"CIFAR-10_Train_Labels.csv\"\n",
    "        self.TRAIN_IMAGES_DIR = self.DATA_DIR / \"train\"\n",
    "        self.TEST_IMAGES_DIR = self.DATA_DIR / \"test\"\n",
    "        self.AUGMENTED_TRAIN_DIR = self.DATA_DIR / \"augmented_train\"\n",
    "\n",
    "        # Training parameters\n",
    "        self.BATCH_SIZE = 32\n",
    "        self.LEARNING_RATE = 0.001\n",
    "        self.EPOCHS = 5\n",
    "        self.NUM_CLASSES = 10\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "\n",
    "        # Data augmentation\n",
    "        self.AUGMENTATIONS_PER_IMAGE = 4\n",
    "        self.SAMPLE_SIZE = 100\n",
    "\n",
    "        # Model parameters\n",
    "        self.DROPOUT_RATE = 0.3\n",
    "        self.L1_FACTOR = 0.0001\n",
    "        self.L2_FACTOR = 0.01\n",
    "\n",
    "        # Early stopping\n",
    "        self.PATIENCE = 5\n",
    "        self.MIN_DELTA = 0.001\n",
    "\n",
    "        # Create necessary directories\n",
    "        self.create_directories()\n",
    "\n",
    "    def create_directories(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        os.makedirs(self.DATA_DIR, exist_ok=True)\n",
    "        os.makedirs(self.MODELS_DIR, exist_ok=True)\n",
    "        os.makedirs(self.AUGMENTED_TRAIN_DIR, exist_ok=True)\n",
    "\n",
    "    def save_config(self, path):\n",
    "        \"\"\"Save configuration to YAML file\"\"\"\n",
    "        config_dict = {k: str(v) if isinstance(v, Path) else v\n",
    "                       for k, v in vars(self).items()\n",
    "                       if not k.startswith('_')}\n",
    "\n",
    "        with open(path, 'w') as f:\n",
    "            yaml.dump(config_dict, f, default_flow_style=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load_config(cls, path):\n",
    "        \"\"\"Load configuration from YAML file\"\"\"\n",
    "        with open(path, 'r') as f:\n",
    "            config_dict = yaml.safe_load(f)\n",
    "\n",
    "        config = cls()\n",
    "        for k, v in config_dict.items():\n",
    "            if hasattr(config, k):\n",
    "                if isinstance(getattr(config, k), Path):\n",
    "                    setattr(config, k, Path(v))\n",
    "                else:\n",
    "                    setattr(config, k, v)\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f3ab3",
   "metadata": {},
   "source": [
    "# preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "class CSVGenerator:\n",
    "    def script_to_generate_csv(self,fileName,base_dir):\n",
    "        # Define the directory for the augmented_train dataset\n",
    "        # base_dir = \"../data/augmented_train\"\n",
    "\n",
    "        # Create a list to hold the rows of the CSV\n",
    "        data_rows = []\n",
    "\n",
    "        # Walk through the directories\n",
    "        for label in os.listdir(base_dir):\n",
    "            label_path = os.path.join(base_dir, label)\n",
    "            if os.path.isdir(label_path):  # Check if it's a directory\n",
    "                for image_name in os.listdir(label_path):\n",
    "                    image_path = os.path.join(label, image_name)  # Relative path for the image\n",
    "                    data_rows.append([image_path, label])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data_rows, columns=[\"image_path\", \"label\"])\n",
    "\n",
    "        # Shuffle the DataFrame rows\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Add an ID column\n",
    "        df.insert(0, \"id\", range(1, len(df) + 1))\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        output_csv_path = f\"../data/{fileName}.csv\"\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "        print(f\"CSV file has been saved at: {output_csv_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CIFAR10PreProcessor:\n",
    "    def __init__(self, train_labels_path, train_images_dir, test_images_dir):\n",
    "        \"\"\"\n",
    "        Initialize the CIFAR10 data processor\n",
    "\n",
    "        Args:\n",
    "            train_labels_path: Path to training labels CSV\n",
    "            train_images_dir: Directory containing training images\n",
    "            test_images_dir: Directory containing test images\n",
    "        \"\"\"\n",
    "        self.train_labels_path = train_labels_path\n",
    "        self.train_images_dir = train_images_dir\n",
    "        self.test_images_dir = test_images_dir\n",
    "        self.train_labels = None\n",
    "        self.load_and_analyze_dataset()\n",
    "\n",
    "\n",
    "    def load_and_analyze_dataset(self):\n",
    "        \"\"\"Load and analyze the dataset, print basic statistics\"\"\"\n",
    "        # Load labels\n",
    "        self.train_labels = pd.read_csv(self.train_labels_path)\n",
    "\n",
    "        # Convert id column to string and add .png extension\n",
    "        self.train_labels['id'] = self.train_labels['id'].astype(str) + '.png'\n",
    "\n",
    "        # Print basic statistics\n",
    "        print(\"Dataset Overview:\")\n",
    "        print(f\"Number of training samples: {len(self.train_labels)}\")\n",
    "        print(f\"Number of training images: {len(os.listdir(self.train_images_dir))}\")\n",
    "        print(f\"Number of testing images: {len(os.listdir(self.test_images_dir))}\")\n",
    "\n",
    "        # Class distribution\n",
    "        class_dist = Counter(self.train_labels['label'])\n",
    "        print(\"\\nClass Distribution:\")\n",
    "        for label, count in class_dist.items():\n",
    "            print(f\"{label}: {count} images ({count / len(self.train_labels) * 100:.2f}%)\")\n",
    "\n",
    "    def normalize_image(self, img):\n",
    "        \"\"\"Normalize image pixel values to range [0,1]\"\"\"\n",
    "        return img.astype('float32') / 255.0\n",
    "\n",
    "    def augment_image(self, img, rotation=True, flip=True, brightness=True, zoom=True):\n",
    "        \"\"\"Apply various augmentation techniques to an image\"\"\"\n",
    "        augmented = img.copy()\n",
    "\n",
    "        if rotation:\n",
    "            angle = np.random.uniform(-15, 15)\n",
    "            height, width = img.shape[:2]\n",
    "            center = (width / 2, height / 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            augmented = cv2.warpAffine(augmented, rotation_matrix, (width, height))\n",
    "\n",
    "        if flip and np.random.random() > 0.5:\n",
    "            augmented = cv2.flip(augmented, 1)\n",
    "\n",
    "        if brightness:\n",
    "            beta = np.random.uniform(-30, 30)\n",
    "            augmented = cv2.convertScaleAbs(augmented, beta=beta)\n",
    "\n",
    "        if zoom:\n",
    "            scale = np.random.uniform(0.8, 1.2)\n",
    "            height, width = img.shape[:2]\n",
    "            center = (width / 2, height / 2)\n",
    "            zoom_matrix = cv2.getRotationMatrix2D(center, 0, scale)\n",
    "            augmented = cv2.warpAffine(augmented, zoom_matrix, (width, height))\n",
    "\n",
    "        return augmented\n",
    "\n",
    "    def load_and_display_images(self, num_samples=5, random_state=None, normalize=True):\n",
    "        \"\"\"Display sample images from the dataset\"\"\"\n",
    "        if random_state is not None:\n",
    "            samples = self.train_labels.sample(n=num_samples, random_state=random_state)\n",
    "        else:\n",
    "            samples = self.train_labels.head(num_samples)\n",
    "\n",
    "        fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            img_name = samples.iloc[i]['id']\n",
    "            label = samples.iloc[i]['label']\n",
    "            img_path = os.path.join(self.train_images_dir, img_name)\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    raise ValueError(f\"Failed to load image: {img_path}\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                orig_img = img.copy()\n",
    "                if normalize:\n",
    "                    img = self.normalize_image(img)\n",
    "\n",
    "                brightness = np.mean(cv2.cvtColor(orig_img, cv2.COLOR_RGB2GRAY))\n",
    "\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f\"Label: {label}\\nBrightness: {brightness:.1f}\")\n",
    "                axes[i].axis(\"off\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_name}: {str(e)}\")\n",
    "                axes[i].text(0.5, 0.5, \"Error loading image\", ha='center')\n",
    "                axes[i].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return fig\n",
    "\n",
    "    def analyze_image_properties(self, sample_size=100, normalize=True):\n",
    "        \"\"\"Analyze properties of images in the dataset\"\"\"\n",
    "        samples = self.train_labels.sample(n=min(sample_size, len(self.train_labels)))\n",
    "\n",
    "        sizes = []\n",
    "        brightness_values = []\n",
    "        pixel_value_ranges = []\n",
    "        corrupted = 0\n",
    "\n",
    "        for _, row in samples.iterrows():\n",
    "            img_path = os.path.join(self.train_images_dir, row['id'])\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    corrupted += 1\n",
    "                    continue\n",
    "\n",
    "                orig_img = img.copy()\n",
    "                if normalize:\n",
    "                    img = self.normalize_image(img)\n",
    "\n",
    "                sizes.append(img.shape)\n",
    "                brightness = np.mean(cv2.cvtColor(orig_img, cv2.COLOR_RGB2GRAY))\n",
    "                brightness_values.append(brightness)\n",
    "\n",
    "                pixel_value_ranges.append({\n",
    "                    'min': img.min(),\n",
    "                    'max': img.max(),\n",
    "                    'mean': img.mean()\n",
    "                })\n",
    "\n",
    "            except Exception:\n",
    "                corrupted += 1\n",
    "\n",
    "        self._print_analysis_results(sample_size, corrupted, sizes, brightness_values,\n",
    "                                     pixel_value_ranges, normalize)\n",
    "\n",
    "        return sizes, brightness_values, pixel_value_ranges\n",
    "\n",
    "    def _print_analysis_results(self, sample_size, corrupted, sizes, brightness_values,\n",
    "                                pixel_value_ranges, normalize):\n",
    "        \"\"\"Helper method to print analysis results\"\"\"\n",
    "        print(\"\\nImage Analysis:\")\n",
    "        print(f\"Sample size: {sample_size}\")\n",
    "        print(f\"Corrupted images: {corrupted}\")\n",
    "        print(f\"Unique image sizes: {set(sizes)}\")\n",
    "        print(f\"Average brightness (original): {np.mean(brightness_values):.2f}\")\n",
    "\n",
    "        if normalize:\n",
    "            pixel_stats = pd.DataFrame(pixel_value_ranges)\n",
    "            print(\"\\nNormalized Pixel Value Statistics:\")\n",
    "            print(f\"Min: {pixel_stats['min'].mean():.3f}\")\n",
    "            print(f\"Max: {pixel_stats['max'].mean():.3f}\")\n",
    "            print(f\"Mean: {pixel_stats['mean'].mean():.3f}\")\n",
    "\n",
    "    def display_augmentations(self, img_index=0, num_augmentations=5):\n",
    "        \"\"\"Display original and augmented versions of an image\"\"\"\n",
    "        img_path = os.path.join(self.train_images_dir, self.train_labels.iloc[img_index]['id'])\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        fig, axes = plt.subplots(1, num_augmentations + 1, figsize=(20, 4))\n",
    "\n",
    "        axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        for i in range(num_augmentations):\n",
    "            augmented = self.augment_image(img)\n",
    "            axes[i + 1].imshow(cv2.cvtColor(augmented, cv2.COLOR_BGR2RGB))\n",
    "            axes[i + 1].set_title(f'Augmented {i + 1}')\n",
    "            axes[i + 1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def create_augmented_dataset(self, subset_size=None, augmentations_per_image=3):\n",
    "        \"\"\"Create augmented dataset\"\"\"\n",
    "        if subset_size:\n",
    "            labels_df = self.train_labels.head(subset_size)\n",
    "        else:\n",
    "            labels_df = self.train_labels\n",
    "\n",
    "        augmented_dataset = []\n",
    "\n",
    "        for idx, row in labels_df.iterrows():\n",
    "            img_path = os.path.join(self.train_images_dir, row['id'])\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                augmented_dataset.append((img, row['label']))\n",
    "\n",
    "                for _ in range(augmentations_per_image):\n",
    "                    aug_img = self.augment_image(img)\n",
    "                    augmented_dataset.append((aug_img, row['label']))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {row['id']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(f\"Processed {idx} images...\")\n",
    "\n",
    "        print(f\"\\nTotal dataset size after augmentation: {len(augmented_dataset)}\")\n",
    "        return augmented_dataset\n",
    "\n",
    "    def create_and_save_augmented_images(self, augmented_dir=\"../data/augmented_train\", augmentations_per_image=4):\n",
    "        \"\"\"\n",
    "        Create and save augmented versions of all images in a new directory\n",
    "\n",
    "        Args:\n",
    "            augmented_dir: Directory where augmented images will be saved\n",
    "            augmentations_per_image: Number of augmented versions to create per original image\n",
    "        \"\"\"\n",
    "        # Create augmented directory if it doesn't exist\n",
    "        os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "        total_images = len(self.train_labels)\n",
    "\n",
    "        for idx, row in self.train_labels.iterrows():\n",
    "            # Create subdirectory for each class\n",
    "            class_dir = os.path.join(augmented_dir, row['label'])\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "            img_path = os.path.join(self.train_images_dir, row['id'])\n",
    "            try:\n",
    "                # Load original image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                # Save original image\n",
    "                original_filename = f\"original_{row['id']}\"\n",
    "                cv2.imwrite(os.path.join(class_dir, original_filename), img)\n",
    "\n",
    "                # Create and save augmented versions\n",
    "                for aug_idx in range(augmentations_per_image):\n",
    "                    aug_img = self.augment_image(img)\n",
    "                    aug_filename = f\"aug{aug_idx + 1}_{row['id']}\"\n",
    "                    cv2.imwrite(os.path.join(class_dir, aug_filename), aug_img)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {row['id']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            # Print progress every 1000 images\n",
    "            if idx % 1000 == 0:\n",
    "                progress = (idx / total_images) * 100\n",
    "                print(f\"Processed {idx}/{total_images} images ({progress:.2f}%)...\")\n",
    "\n",
    "        print(\"\\nAugmentation complete!\")\n",
    "        print(f\"Images saved in: {augmented_dir}\")\n",
    "\n",
    "        # Print directory structure summary\n",
    "        class_counts = {}\n",
    "        for class_name in os.listdir(augmented_dir):\n",
    "            class_path = os.path.join(augmented_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                num_images = len(os.listdir(class_path))\n",
    "                class_counts[class_name] = num_images\n",
    "\n",
    "        print(\"\\nAugmented Dataset Summary:\")\n",
    "        for class_name, count in class_counts.items():\n",
    "            print(f\"{class_name}: {count} images\")\n",
    "\n",
    "    def prepare_training_dataset(self, output_dir=\"../data/final_train_dataset\"):\n",
    "        \"\"\"\n",
    "        Prepare a combined training dataset from original and augmented images\n",
    "\n",
    "        Args:\n",
    "            output_dir: Directory where the final training dataset will be created\n",
    "\n",
    "        Returns:\n",
    "            DataFrame containing paths and labels for the new training dataset\n",
    "        \"\"\"\n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Initialize list to store image information\n",
    "        dataset_info = []\n",
    "\n",
    "        # Process original training images\n",
    "        print(\"Processing original training images...\")\n",
    "        for idx, row in self.train_labels.iterrows():\n",
    "            try:\n",
    "                # Load and process original image\n",
    "                orig_path = os.path.join(self.train_images_dir, row['id'])\n",
    "                if os.path.exists(orig_path):\n",
    "                    # Create class directory if it doesn't exist\n",
    "                    class_dir = os.path.join(output_dir, row['label'])\n",
    "                    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "                    # Copy original image with new name\n",
    "                    new_filename = f\"orig_{row['id']}\"\n",
    "                    new_path = os.path.join(class_dir, new_filename)\n",
    "                    img = cv2.imread(orig_path)\n",
    "                    if img is not None:\n",
    "                        cv2.imwrite(new_path, img)\n",
    "                        dataset_info.append({\n",
    "                            'path': new_path,\n",
    "                            'label': row['label'],\n",
    "                            'type': 'original'\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing original image {row['id']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(f\"Processed {idx} original images...\")\n",
    "\n",
    "        # Process augmented images\n",
    "        print(\"\\nProcessing augmented images...\")\n",
    "        augmented_dir = \"../data/augmented_train\"\n",
    "\n",
    "        for class_name in os.listdir(augmented_dir):\n",
    "            class_path = os.path.join(augmented_dir, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            # Create class directory in output\n",
    "            output_class_dir = os.path.join(output_dir, class_name)\n",
    "            os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "            # Process augmented images for this class\n",
    "            for img_name in os.listdir(class_path):\n",
    "                if img_name.startswith('aug'):  # Only process augmented images\n",
    "                    try:\n",
    "                        aug_path = os.path.join(class_path, img_name)\n",
    "                        new_path = os.path.join(output_class_dir, img_name)\n",
    "\n",
    "                        img = cv2.imread(aug_path)\n",
    "                        if img is not None:\n",
    "                            cv2.imwrite(new_path, img)\n",
    "                            dataset_info.append({\n",
    "                                'path': new_path,\n",
    "                                'label': class_name,\n",
    "                                'type': 'augmented'\n",
    "                            })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing augmented image {img_name}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "        # Create DataFrame with dataset information\n",
    "        dataset_df = pd.DataFrame(dataset_info)\n",
    "\n",
    "        # Save dataset information to CSV\n",
    "        csv_path = os.path.join(output_dir, 'training_dataset_info.csv')\n",
    "        dataset_df.to_csv(csv_path, index=False)\n",
    "\n",
    "        # Print summary statistics\n",
    "        print(\"\\nDataset Summary:\")\n",
    "        print(f\"Total images: {len(dataset_df)}\")\n",
    "        print(\"\\nImages per class:\")\n",
    "        class_counts = dataset_df['label'].value_counts()\n",
    "        for label, count in class_counts.items():\n",
    "            print(f\"{label}: {count}\")\n",
    "\n",
    "        print(\"\\nImages by type:\")\n",
    "        type_counts = dataset_df['type'].value_counts()\n",
    "        for type_name, count in type_counts.items():\n",
    "            print(f\"{type_name}: {count}\")\n",
    "\n",
    "        print(f\"\\nDataset information saved to: {csv_path}\")\n",
    "\n",
    "        return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fed0c",
   "metadata": {},
   "source": [
    "# dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cc522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from modelRegularization import ModelRegularization, apply_regularization\n",
    "\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Custom Dataset for CIFAR-10 images.\n",
    "        \n",
    "        Args:\n",
    "            csv_file: Path to the csv file with annotations\n",
    "            img_dir: Directory with all the images\n",
    "            transform: Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {\n",
    "            'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "            'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(\n",
    "            self.img_dir, self.data_frame.iloc[idx]['image_path'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.class_to_idx[self.data_frame.iloc[idx]['label']]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a067db",
   "metadata": {},
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df844cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self, num_classes=10, conv_filters=[32, 64, 128], dropout_rate=0.3, fc_units=512):\n",
    "        super(CIFAR10Model, self).__init__()\n",
    "\n",
    "        self.conv1 = self._make_conv_block(3, conv_filters[0], dropout_rate)\n",
    "        self.conv2 = self._make_conv_block(\n",
    "            conv_filters[0], conv_filters[1], dropout_rate)\n",
    "        self.conv3 = self._make_conv_block(\n",
    "            conv_filters[1], conv_filters[2], dropout_rate)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_filters[2] * 4 * 4, fc_units),\n",
    "            nn.BatchNorm1d(fc_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(fc_units, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_conv_block(self, in_channels, out_channels, dropout_rate):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b85aa",
   "metadata": {},
   "source": [
    "# modelRegularization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4522c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ModelRegularization:\n",
    "    def __init__(self, model: nn.Module, patience: int = 5, min_delta: float = 0.001,\n",
    "                 l1_factor: float = 0.0, l2_factor: float = 0.01):\n",
    "        \"\"\"\n",
    "        Initialize regularization and early stopping functionality.\n",
    "        \n",
    "        Args:\n",
    "            model: The neural network model\n",
    "            patience: Number of epochs to wait for improvement before early stopping\n",
    "            min_delta: Minimum change in monitored quantity to qualify as an improvement\n",
    "            l1_factor: L1 regularization factor\n",
    "            l2_factor: L2 regularization factor\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.l1_factor = l1_factor\n",
    "        self.l2_factor = l2_factor\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.history: Dict[str, List[float]] = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_acc': [], 'val_acc': []\n",
    "        }\n",
    "        \n",
    "    def should_stop(self, val_loss: float) -> bool:\n",
    "        \"\"\"Check if training should stop based on validation loss.\"\"\"\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            return False\n",
    "            \n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def compute_regularization_loss(self) -> torch.Tensor:\n",
    "        \"\"\"Compute L1 and L2 regularization losses.\"\"\"\n",
    "        l1_loss = torch.tensor(0., device=next(self.model.parameters()).device)\n",
    "        l2_loss = torch.tensor(0., device=next(self.model.parameters()).device)\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            if param.requires_grad:\n",
    "                l1_loss += torch.sum(torch.abs(param))\n",
    "                l2_loss += torch.sum(param.pow(2))\n",
    "        \n",
    "        return self.l1_factor * l1_loss + self.l2_factor * l2_loss\n",
    "    \n",
    "    def update_history(self, train_loss: float, val_loss: float, \n",
    "                      train_acc: float, val_acc: float) -> None:\n",
    "        \"\"\"Update training history.\"\"\"\n",
    "        self.history['train_loss'].append(train_loss)\n",
    "        self.history['val_loss'].append(val_loss)\n",
    "        self.history['train_acc'].append(train_acc)\n",
    "        self.history['val_acc'].append(val_acc)\n",
    "    \n",
    "    def plot_training_history(self, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot training history.\"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history['train_loss'], label='Train Loss')\n",
    "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history['train_acc'], label='Train Accuracy')\n",
    "        plt.plot(self.history['val_acc'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "        plt.show()\n",
    "    \n",
    "    def check_overfitting(self, threshold: float = 0.1) -> Tuple[bool, float]:\n",
    "        \"\"\"\n",
    "        Check if model is overfitting based on train/val performance gap.\n",
    "        \n",
    "        Args:\n",
    "            threshold: Maximum acceptable difference between train and val accuracy\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (is_overfitting, gap)\n",
    "        \"\"\"\n",
    "        if len(self.history['train_acc']) < 2:\n",
    "            return False, 0.0\n",
    "            \n",
    "        train_acc = self.history['train_acc'][-1]\n",
    "        val_acc = self.history['val_acc'][-1]\n",
    "        gap = train_acc - val_acc\n",
    "        \n",
    "        return gap > threshold, gap\n",
    "\n",
    "    def get_learning_curves(self) -> Dict[str, List[float]]:\n",
    "        \"\"\"Get learning curves data.\"\"\"\n",
    "        return self.history\n",
    "\n",
    "def apply_regularization(model: nn.Module) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Apply regularization techniques to model architecture.\n",
    "    \n",
    "    Args:\n",
    "        model: Original model\n",
    "        \n",
    "    Returns:\n",
    "        Modified model with regularization\n",
    "    \"\"\"\n",
    "    # Add dropout layers if not present\n",
    "    def add_dropout(module):\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, (nn.Linear, nn.Conv2d)):\n",
    "                module._modules[name] = nn.Sequential(\n",
    "                    child,\n",
    "                    nn.Dropout(p=0.3)\n",
    "                )\n",
    "            else:\n",
    "                add_dropout(child)\n",
    "    \n",
    "    # Add batch normalization if not present\n",
    "    def add_batchnorm(module):\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, nn.Conv2d):\n",
    "                module._modules[name] = nn.Sequential(\n",
    "                    child,\n",
    "                    nn.BatchNorm2d(child.out_channels)\n",
    "                )\n",
    "            elif isinstance(child, nn.Linear):\n",
    "                module._modules[name] = nn.Sequential(\n",
    "                    child,\n",
    "                    nn.BatchNorm1d(child.out_features)\n",
    "                )\n",
    "            else:\n",
    "                add_batchnorm(child)\n",
    "    \n",
    "    model_copy = type(model)()  # Create new instance of same model type\n",
    "    model_copy.load_state_dict(model.state_dict())\n",
    "    \n",
    "    add_dropout(model_copy)\n",
    "    add_batchnorm(model_copy)\n",
    "    \n",
    "    return model_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c578749a",
   "metadata": {},
   "source": [
    "# pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123de9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from preprocessing import CIFAR10PreProcessor, CSVGenerator\n",
    "from trainer import CIFAR10Trainer\n",
    "from config import TrainingConfig\n",
    "\n",
    "\n",
    "class CIFAR10Pipeline:\n",
    "    \"\"\"Pipeline class for handling training workflow\"\"\"\n",
    "\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.device = self.get_device()\n",
    "        self.trainer = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_device():\n",
    "        \"\"\"Set up and return the appropriate device for training\"\"\"\n",
    "\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device('mps')\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device('cuda')\n",
    "        else:\n",
    "            return torch.device('cpu')\n",
    "\n",
    "    def preprocess_data(self, augment_data=True):\n",
    "        \"\"\"Handle data preprocessing and augmentation\"\"\"\n",
    "        processor = CIFAR10PreProcessor(\n",
    "            self.config.TRAIN_LABELS_PATH,\n",
    "            self.config.TRAIN_IMAGES_DIR,\n",
    "            self.config.TEST_IMAGES_DIR\n",
    "        )\n",
    "\n",
    "        # Analyze and display data properties\n",
    "        processor.load_and_display_images(num_samples=5, random_state=42)\n",
    "        sizes, brightness, pixel_ranges = processor.analyze_image_properties(\n",
    "            sample_size=self.config.SAMPLE_SIZE\n",
    "        )\n",
    "\n",
    "        if augment_data:\n",
    "            # Create augmented dataset\n",
    "            processor.create_and_save_augmented_images(\n",
    "                augmented_dir=str(self.config.AUGMENTED_TRAIN_DIR),\n",
    "                augmentations_per_image=self.config.AUGMENTATIONS_PER_IMAGE\n",
    "            )\n",
    "\n",
    "            # Generate CSV for augmented data\n",
    "            generator = CSVGenerator()\n",
    "            generator.script_to_generate_csv(\n",
    "                fileName=\"train_labels\",\n",
    "                base_dir=str(self.config.AUGMENTED_TRAIN_DIR)\n",
    "            )\n",
    "\n",
    "    def train_model(self, hypertune=False):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.trainer = CIFAR10Trainer(\n",
    "            train_csv=str(self.config.DATA_DIR / \"train_labels.csv\"),\n",
    "            train_dir=str(self.config.AUGMENTED_TRAIN_DIR),\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            learning_rate=self.config.LEARNING_RATE,\n",
    "            num_classes=self.config.NUM_CLASSES,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # Add hyperparameter tuning\n",
    "        self.trainer.tune_hyperparameters(train_csv=str(self.config.DATA_DIR / \"train_labels.csv\"),\n",
    "                                          train_dir=str(self.config.AUGMENTED_TRAIN_DIR)) if hypertune else None\n",
    "\n",
    "        self.trainer.train(\n",
    "            epochs=self.config.EPOCHS,\n",
    "            # save_dir=str(self.config.MODELS_DIR)\n",
    "            save_dir=str(\"hyper-models\")\n",
    "        )\n",
    "\n",
    "    def predict_image(self, image_path):\n",
    "        \"\"\"Make prediction for a single image\"\"\"\n",
    "        if self.trainer is None:\n",
    "            raise ValueError(\n",
    "                \"Model not trained. Please train the model first.\")\n",
    "\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        prediction = self.trainer.predict(image_path)\n",
    "        print(f'Predicted class: {class_names[prediction]}')\n",
    "        return class_names[prediction]\n",
    "\n",
    "    def load_trained_model(self, model_path=None):\n",
    "        \"\"\"Load a trained model\"\"\"\n",
    "        if model_path is None:\n",
    "            model_path = self.config.MODELS_DIR / 'best_model.pt'\n",
    "\n",
    "        if self.trainer is None:\n",
    "            self.trainer = CIFAR10Trainer(\n",
    "                train_csv=str(self.config.DATA_DIR / \"train_labels.csv\"),\n",
    "                train_dir=str(self.config.AUGMENTED_TRAIN_DIR),\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                learning_rate=self.config.LEARNING_RATE,\n",
    "                num_classes=self.config.NUM_CLASSES,\n",
    "                device=self.device\n",
    "            )\n",
    "\n",
    "        self.trainer.load_model(str(model_path))\n",
    "\n",
    "    def predict_test_directory(self, output_csv=\"predictions.csv\"):\n",
    "        \"\"\"Predict classes for all test images and save results\"\"\"\n",
    "        if self.trainer is None:\n",
    "            raise ValueError(\n",
    "                \"Model not trained. Please load or train the model first.\")\n",
    "\n",
    "        predictions_df = self.trainer.predict_test_directory(\n",
    "            test_dir=str(self.config.TEST_IMAGES_DIR),\n",
    "            output_csv=output_csv\n",
    "        )\n",
    "        return predictions_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1427a52",
   "metadata": {},
   "source": [
    "# trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece656cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from modelRegularization import ModelRegularization, apply_regularization\n",
    "from dataset import CIFAR10Dataset\n",
    "from model import CIFAR10Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "class CIFAR10Trainer:\n",
    "    def __init__(self, train_csv, train_dir, batch_size=32, learning_rate=0.001,\n",
    "                 num_classes=10, device=None):\n",
    "        \"\"\"\n",
    "        Initialize the trainer with regularization.\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Set device\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                                       else \"cuda\" if torch.cuda.is_available()\n",
    "                                       else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        # Create transforms with augmentation\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        # Setup datasets and dataloaders\n",
    "        self.setup_data(train_csv, train_dir)\n",
    "\n",
    "        # Initialize model with regularization\n",
    "        self.model = apply_regularization(CIFAR10Model(\n",
    "            num_classes=num_classes)).to(self.device)\n",
    "\n",
    "        # Setup loss, optimizer and learning rate scheduler\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=0.01  # L2 regularization\n",
    "        )\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='min',\n",
    "            factor=0.2,\n",
    "            patience=3,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        # Initialize regularization handler\n",
    "        self.regularization = ModelRegularization(\n",
    "            model=self.model,\n",
    "            patience=5,\n",
    "            min_delta=0.001,\n",
    "            l1_factor=0.0001,\n",
    "            l2_factor=0.01\n",
    "        )\n",
    "\n",
    "    def tune_hyperparameters(self, train_csv, train_dir):\n",
    "        \"\"\"Experiment with different hyperparameters\"\"\"\n",
    "        self.train_csv = train_csv  # Store paths\n",
    "        self.train_dir = train_dir\n",
    "        configs = [\n",
    "            {\n",
    "                'optimizer': ('AdamW', {'lr': 0.001, 'weight_decay': 0.01}),\n",
    "                'conv_filters': [32, 64, 128],\n",
    "                'dropout_rate': 0.3,\n",
    "                'batch_size': 32\n",
    "            },\n",
    "            {\n",
    "                'optimizer': ('SGD', {'lr': 0.01, 'momentum': 0.9}),\n",
    "                'conv_filters': [64, 128, 256],\n",
    "                'dropout_rate': 0.5,\n",
    "                'batch_size': 64\n",
    "            },\n",
    "            {\n",
    "                'optimizer': ('Adam', {'lr': 0.0005}),\n",
    "                'conv_filters': [16, 32, 64],\n",
    "                'dropout_rate': 0.2,\n",
    "                'batch_size': 128\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        results = []\n",
    "        for config in tqdm(configs, desc=\"Testing configurations\"):\n",
    "            # Initialize model with config\n",
    "            model = CIFAR10Model(\n",
    "                num_classes=self.num_classes,\n",
    "                conv_filters=config['conv_filters'],\n",
    "                dropout_rate=config['dropout_rate']\n",
    "            ).to(self.device)\n",
    "\n",
    "            # Setup optimizer\n",
    "            opt_name, opt_params = config['optimizer']\n",
    "            optimizer_class = getattr(optim, opt_name)\n",
    "            optimizer = optimizer_class(model.parameters(), **opt_params)\n",
    "\n",
    "            # Train and evaluate\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "            self.batch_size = config['batch_size']\n",
    "            self.setup_data(self.train_csv, self.train_dir)\n",
    "\n",
    "            # Train for fewer epochs during tuning\n",
    "            metrics = self.train(epochs=5)\n",
    "\n",
    "            results.append({\n",
    "                'config': config,\n",
    "                'metrics': metrics\n",
    "            })\n",
    "            print(\"Hyperparameter tuning:\")\n",
    "            print(f\"Config: {config}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def setup_data(self, train_csv, train_dir, val_split=0.2):\n",
    "        \"\"\"Setup train and validation datasets and dataloaders\"\"\"\n",
    "        dataset = CIFAR10Dataset(train_csv, train_dir, self.train_transform)\n",
    "\n",
    "        train_size = int((1 - val_split) * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            dataset, [train_size, val_size]\n",
    "        )\n",
    "\n",
    "        val_dataset.dataset.transform = self.val_transform\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch with regularization\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}')\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "\n",
    "            # Add regularization loss\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            reg_loss = self.regularization.compute_regularization_loss()\n",
    "            total_loss = loss + reg_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss/len(self.train_loader),\n",
    "                'acc': 100.*correct/total\n",
    "            })\n",
    "\n",
    "        return running_loss/len(self.train_loader), 100.*correct/total\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.val_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        return running_loss/len(self.val_loader), 100.*correct/total\n",
    "\n",
    "    def train(self, epochs=50, save_dir='models'):\n",
    "        \"\"\"Train the model with regularization and early stopping\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        best_val_acc = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss, train_acc = self.train_epoch(epoch)\n",
    "            val_loss, val_acc = self.validate()\n",
    "\n",
    "            # Update regularization history\n",
    "            self.regularization.update_history(\n",
    "                train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "            # Check for overfitting\n",
    "            is_overfitting, gap = self.regularization.check_overfitting()\n",
    "            if is_overfitting:\n",
    "                print(\n",
    "                    f\"Warning: Possible overfitting detected (gap: {gap:.2f}%)\")\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            print(f'Epoch {epoch}:')\n",
    "            print(\n",
    "                f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                self.save_model(os.path.join(save_dir, 'best_model.pt'))\n",
    "                print(f'Saved model with val_acc: {val_acc:.2f}%')\n",
    "\n",
    "            # Early stopping check\n",
    "            if self.regularization.should_stop(val_loss):\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "            print('-' * 70)\n",
    "\n",
    "        # Plot training history\n",
    "        self.regularization.plot_training_history(\n",
    "            save_path=os.path.join(save_dir, 'training_history.png')\n",
    "        )\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the model\"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "        }, path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        \"\"\"Load the model with weights_only=True\"\"\"\n",
    "        checkpoint = torch.load(\n",
    "            path, map_location=self.device, weights_only=True)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Predict class for a single image\"\"\"\n",
    "        self.model.eval()\n",
    "        transform = self.val_transform\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(image)\n",
    "            _, predicted = output.max(1)\n",
    "\n",
    "        return predicted.item()\n",
    "\n",
    "    def predict_test_directory(self, test_dir, output_csv=\"predictions.csv\"):\n",
    "        \"\"\"Predict classes for all images in test directory and save to CSV.\"\"\"\n",
    "        idx_to_class = {\n",
    "            0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
    "            5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'\n",
    "        }\n",
    "\n",
    "        predictions = []\n",
    "        image_files = sorted([f for f in os.listdir(test_dir)\n",
    "                              if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "        for image_file in tqdm(image_files, desc=\"Predicting test images\"):\n",
    "            image_path = os.path.join(test_dir, image_file)\n",
    "            try:\n",
    "                class_idx = self.predict(str(image_path))\n",
    "                predictions.append({\n",
    "                    'image_name': image_file,\n",
    "                    'predicted_class': idx_to_class[class_idx]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error predicting {image_file}: {str(e)}\")\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions)\n",
    "        predictions_df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\nPredictions saved to {output_csv}\")\n",
    "        return predictions_df\n",
    "\n",
    "    def compute_validation_metrics(self):\n",
    "        \"\"\"Compute all evaluation metrics using validation set\"\"\"\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        self.model.eval()\n",
    "\n",
    "        # Collect predictions\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.val_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = outputs.max(1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Weighted Precision: {precision:.4f}\")\n",
    "        print(f\"Weighted Recall: {recall:.4f}\")\n",
    "        print(f\"Weighted F1-Score: {f1:.4f}\")\n",
    "\n",
    "        # Detailed report and confusion matrix\n",
    "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        report = classification_report(\n",
    "            all_labels, all_preds, target_names=class_names)\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(report)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Validation Set Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('validation_confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot training history\n",
    "        self.regularization.plot_training_history('training_history.png')\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'detailed_report': report,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1465b0",
   "metadata": {},
   "source": [
    "# test_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def test_pytorch_setup():\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "    \n",
    "    # Test device availability\n",
    "    print(\"\\nDevice Information:\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "    \n",
    "    # Create a simple tensor and test device movement\n",
    "    device = get_device()\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    \n",
    "    x = torch.randn(2, 3)\n",
    "    try:\n",
    "        x = x.to(device)\n",
    "        print(\"Successfully created and moved tensor to device\")\n",
    "        print(x)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when testing tensor operations: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_pytorch_setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817e0cd",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from config import TrainingConfig\n",
    "from pipeline import CIFAR10Pipeline\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load or create configuration\n",
    "    config_path = Path(\"config.yaml\")\n",
    "    if config_path.exists():\n",
    "        config = TrainingConfig.load_config(config_path)\n",
    "    else:\n",
    "        config = TrainingConfig()\n",
    "        config.save_config(config_path)\n",
    "\n",
    "    # Initialize pipeline\n",
    "    pipeline = CIFAR10Pipeline(config)\n",
    "\n",
    "    # Step 1: Preprocess and augment data\n",
    "    # Comment out if preprocessing is already done\n",
    "    # pipeline.preprocess_data()\n",
    "\n",
    "\n",
    "    # Step 2: Train model\n",
    "    pipeline.train_model(hypertune=True)\n",
    "\n",
    "    # Step 3: Make predictions\n",
    "    pipeline.load_trained_model(\"models/best_model.pt\")\n",
    "    # metrics_report, confusion_mat = pipeline.trainer.compute_validation_metrics()\n",
    "    metrics = pipeline.trainer.compute_validation_metrics()\n",
    "    print(\"Validation metrics: \", metrics, \"\\n\")\n",
    "    # predictions_df = pipeline.predict_test_directory(\"data/predictions.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
